{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compte Rendu : Projet TC4 - BIARD David & BERRIEN Samuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle complètement naïf (TP 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Compte le nombre d'occurence de chaque mot\n",
    "def mkCountWord(data):\n",
    "    vocab = {}\n",
    "    for phrase in data:\n",
    "        for mot in phrase:\n",
    "            if mot[0] in vocab:\n",
    "                vocab[mot[0]] += 1\n",
    "            else:\n",
    "                vocab[mot[0]] = 1\n",
    "    return vocab\n",
    "\n",
    "# Comptre le nombre d'occurence de chaque tags et retourn la liste de tous les tags\n",
    "def allTags(data):\n",
    "    tags = {}\n",
    "    for phrase in data:\n",
    "        for mot in phrase:\n",
    "            if mot[1] in tags:\n",
    "                tags[mot[1]] += 1\n",
    "            else:\n",
    "                tags[mot[1]] = 1\n",
    "    l_tags = np.array([t for t in tags.keys()])\n",
    "    return tags, l_tags\n",
    "\n",
    "# Compte le nombre de pairs (x, y) dans les données de train\n",
    "def pair_count(data_train):\n",
    "    res = {}\n",
    "    for phrase in data_train:\n",
    "        for t_u in phrase:\n",
    "            if t_u in res:\n",
    "                res[t_u] += 1\n",
    "            else:\n",
    "                res[t_u] = 1\n",
    "    return res\n",
    "\n",
    "# Calcul P(Y = y | X = x)\n",
    "def p_y_sachant_x(count_of_pairs, count_words, y, x):\n",
    "    if (x, y) in count_of_pairs:\n",
    "        return round(count_of_pairs[(x, y)] / count_words[x], 3)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# Calcul la probabilité ci-dessus pour tous les tags de la listes de tags\n",
    "def vect_prob_for_all_y(count_of_pairs, count_words, l_tags, x):\n",
    "    res = [(y, p_y_sachant_x(count_of_pairs, count_words, y, x)) for y in l_tags]\n",
    "    return res\n",
    "\n",
    "# Tri les prédictions pour obtenir la plus élevée\n",
    "def prediction(vect_prob):\n",
    "    res = sorted(vect_prob,key=lambda x: x[1], reverse=True)[0]\n",
    "    return res[0]\n",
    "\n",
    "# Evaluation des performances du modèle\n",
    "def eval_model(data_test, data_train, count_of_pairs, count_words, l_tags):\n",
    "    nb_error = 0\n",
    "    for phrases in data_test:\n",
    "        for t_u in phrases:\n",
    "            x = t_u[0]\n",
    "            out = prediction(vect_prob_for_all_y(count_of_pairs, count_words, l_tags, x))\n",
    "            if(out != t_u[1]):\n",
    "                nb_error += 1\n",
    "    accuracy = ((1 - nb_error / (len(np.array(data_test).sum())))*100)\n",
    "    return round(accuracy,1)\n",
    "\n",
    "# Transforme les données à l'aider des fonctions décrites ci-dessus\n",
    "def process_data(data_train, n):\n",
    "    count = mkCountWord(data_train)\n",
    "    list_winf10 = [k for k, v in count.items() if v > n]\n",
    "    new_data_train = [[t_u for t_u in l if t_u[0] in list_winf10] for l in data_train]\n",
    "    return new_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des paramètres servant aux prédiction du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_params(data):\n",
    "    tags, l_tags = allTags(data)\n",
    "    count_words = mkCountWord(data)\n",
    "    count_of_pairs = pair_count(data)\n",
    "    return tags, l_tags, count_words, count_of_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle HMM (first & second Order) TP2 &TP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description de la classe HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Some words in test could be unseen during training, or out of the vocabulary (OOV) even during the training. \n",
    "# To manage OOVs, all words out the vocabulary are mapped on a special token: UNK defined as follows: \n",
    "UNK = \"<unk>\" \n",
    "UNKid = 0 \n",
    "\n",
    "class HMM:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba_2 = None,\n",
    "                 transition_proba_3 = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None):\n",
    "            \"\"\"Builds a new Hidden Markov Model\n",
    "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            transition_proba is the transition probability matrix\n",
    "                [a_ij] a_ij = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
    "            observation_proba is the observation probablility matrix\n",
    "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
    "            initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print(\"HMM created with: \")\n",
    "            self.N = len(state_list) # The number of states\n",
    "            self.M = len(observation_list) # The number of words in the vocabulary\n",
    "            print(str(self.N)+\" states\")\n",
    "            print(str(self.M)+\" observations\")\n",
    "            self.omega_Y = state_list # Keep the vocabulary of tags\n",
    "            self.omega_X = observation_list # Keep the vocabulary of words\n",
    "            # Init. of the 3 distributions : observation, transition and initial states\n",
    "            if transition_proba_3 is None:\n",
    "                self.transition_proba_3 = np.zeros( (self.N, self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba_3=transition_proba_3\n",
    "            if transition_proba_2 is None:\n",
    "                self.transition_proba_2 = np.zeros( (self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba_2=transition_proba_2\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = np.zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = np.zeros( (self.N, self.N), float ) # pi\n",
    "            else:\n",
    "                self.initial_state_proba = initial_state_proba\n",
    "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
    "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
    "            # to keep the mapping between strings (word or tag) and indices. \n",
    "            self.make_indexes()\n",
    "            self.compute_matrix()\n",
    "\n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities arrays\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "        \n",
    "        # Fonction initialisant les matrices de paramètres à l'aide des dictionnaire\n",
    "        # passés en paramètres\n",
    "        def compute_matrix(self):\n",
    "            trans3 = np.zeros( (self.N, self.N, self.N), float)\n",
    "            for (y1, y2, y3), v in self.transition_proba_3.items():\n",
    "                trans3[self.Y_index[y1], self.Y_index[y2], self.Y_index[y3]] = v\n",
    "            self.transition_proba_3 = trans3\n",
    "            \n",
    "            trans2 = np.zeros( (self.N, self.N), float)\n",
    "            for (y1, y2), v in self.transition_proba_2.items():\n",
    "                trans2[self.Y_index[y1], self.Y_index[y2]] = v\n",
    "            self.transition_proba_2 = trans2\n",
    "            \n",
    "            obs = np.zeros( (self.M, self.N), float)            \n",
    "            for (x, y), v in self.observation_proba.items():\n",
    "                obs[self.X_index[x], self.Y_index[y]] = v\n",
    "            self.observation_proba = obs\n",
    "            \n",
    "            init0 = np.zeros( (self.N,), float )\n",
    "            for y, v in self.initial_state_proba.items():\n",
    "                init0[self.Y_index[y]] = v\n",
    "            self.initial_state_proba = init0\n",
    "        \n",
    "        # Algorithme de Viterbi au premier ordre\n",
    "        def viterbi_first_order(self, seq):\n",
    "            mu = [{}]\n",
    "            path = {}\n",
    "            for y in self.omega_Y:\n",
    "                mu[0][y] = self.initial_state_proba[self.Y_index[y]] * \\\n",
    "                            self.observation_proba[self.X_index[seq[0][0]]][self.Y_index[y]]\n",
    "                path[y] = [y]\n",
    "\n",
    "            for t in range(1, len(seq)):\n",
    "                mu.append({})\n",
    "                newpath = {}\n",
    "                indexed_word = seq[t][0]        \n",
    "                for y in self.omega_Y:\n",
    "                    tmp = []\n",
    "                    for y0 in self.omega_Y:\n",
    "                        a = (mu[t-1][y0] * self.transition_proba_2[self.Y_index[y]][self.Y_index[y0]] * \\\n",
    "                             self.observation_proba[self.X_index[indexed_word]][self.Y_index[y]], y0)\n",
    "                        tmp.append(a)\n",
    "                    prob, state = max(tmp)\n",
    "                    mu[t][y] = prob\n",
    "                    newpath[y] = path[state] + [y]\n",
    "                path = newpath\n",
    "\n",
    "            prob, state = max((mu[len(seq)-1][y], y) for y in self.omega_Y)\n",
    "            return path[state]\n",
    "        \n",
    "        # Algorithme de Viterbi au second ordre\n",
    "        def viterbi_second_order(self, seq):\n",
    "                \n",
    "            d = []\n",
    "            c = []\n",
    "\n",
    "            for k in range(len(seq)):\n",
    "                c.append(np.zeros((len(self.omega_Y), len(self.omega_Y))))\n",
    "                if k == 0:\n",
    "                    d.append(np.zeros((len(self.omega_Y))))\n",
    "                else:\n",
    "                    d.append(np.zeros((len(self.omega_Y), len(self.omega_Y))))\n",
    "\n",
    "            for l in range(len(self.omega_Y)):\n",
    "                d[0][l] = self.initial_state_proba[l] * \\\n",
    "                          self.observation_proba[self.X_index[seq[0][0]]][l]\n",
    "\n",
    "            if len(seq) > 1:\n",
    "                for l in range(len(self.omega_Y)):\n",
    "                    for m in range(len(self.omega_Y)):\n",
    "                        d[1][l, m] = d[0][l] * self.transition_proba_2[m][l] * \\\n",
    "                                     self.observation_proba[self.X_index[seq[1][0]]][m]\n",
    "\n",
    "            for i in range(2, len(seq)):\n",
    "                for m in range(len(self.omega_Y)):\n",
    "                    for n in range(len(self.omega_Y)):\n",
    "                        tmp_max_d = np.zeros((len(self.omega_Y)))\n",
    "                        tmp_argmax_c = np.zeros((len(self.omega_Y)))\n",
    "                        for l in range(len(self.omega_Y)):\n",
    "                            d_tmp = d[i-1][l, m] * \\\n",
    "                                    self.transition_proba_3[n][m][l] * \\\n",
    "                                    self.observation_proba[self.X_index[seq[i][0]]][n]\n",
    "                            c_tmp = d[i-1][l, m] * self.transition_proba_3[n][m][l]\n",
    "                            tmp_max_d[l] = d_tmp\n",
    "                            tmp_argmax_c[l] = c_tmp\n",
    "                        d[i][m, n] = np.max(tmp_max_d)\n",
    "                        c[i][m, n] = np.argmax(tmp_argmax_c)\n",
    "\n",
    "            K = len(seq) - 1\n",
    "            x = [None] * len(seq)\n",
    "\n",
    "            if len(seq) == 1:\n",
    "                k_state = np.unravel_index(np.argmax(d[K], axis=None), d[K].shape)\n",
    "                f_state = k_state[0]\n",
    "                x[K] = self.omega_Y[f_state]\n",
    "            else:\n",
    "                k_kMoinsUn_states = np.unravel_index(np.argmax(d[K], axis=None), d[K].shape)\n",
    "                k_state_index = k_kMoinsUn_states[1]\n",
    "                kMoinsUn_state_index = k_kMoinsUn_states[0]\n",
    "                x[K] = self.omega_Y[k_state_index]\n",
    "                x[K-1] = self.omega_Y[kMoinsUn_state_index]\n",
    "\n",
    "            for i in range(K-2, -1, -1):\n",
    "                index = c[i+2][self.Y_index[x[i+1]], self.Y_index[x[i+2]]]\n",
    "                index = int(index)\n",
    "                x[i] = self.omega_Y[index]\n",
    "\n",
    "            return x\n",
    "        \n",
    "        # Fonction évaluant les performance du modèle HMM premier ordre\n",
    "        def evaluate_fst_order(self, data):\n",
    "            error = 0\n",
    "            error_produced = 0\n",
    "            error_corrected = 0\n",
    "            total = 0\n",
    "            for i, seq in enumerate(data):\n",
    "                res = self.viterbi_first_order(seq)\n",
    "                for y_pred, (x, y) in list(zip(res, seq)):\n",
    "                    if x != y and y_pred == y:\n",
    "                        error_corrected += 1\n",
    "                    if x == y and y_pred != y:\n",
    "                        error_produced += 1\n",
    "                    error += 1 if y_pred != y else 0\n",
    "                    total += 1\n",
    "            print(\"The accuracy of the model(HMM first order) is : \", round((1 - error / total)*100, 2), \" %\")\n",
    "            print(\"The number of error produced is : \", error_produced)\n",
    "            print(\"The number of typed error corrected is : \", error_corrected)\n",
    "        \n",
    "        # Fonction évaluant les performance du modèle HMM second ordre\n",
    "        def evaluate_scd_order(self, data):\n",
    "            error = 0\n",
    "            error_produced = 0\n",
    "            error_corrected = 0\n",
    "            total = 0\n",
    "            for i, seq in enumerate(data):\n",
    "                res = self.viterbi_second_order(seq)\n",
    "                for y_pred, (x, y) in list(zip(res, seq)):\n",
    "                    if x != y and y_pred == y:\n",
    "                        error_corrected += 1\n",
    "                    if x == y and y_pred != y:\n",
    "                        error_produced += 1\n",
    "                    error += 1 if y_pred != y else 0\n",
    "                    total += 1\n",
    "            print(\"The accuracy of the model(HMM second order) is : \", round((1 - error / total)*100, 2), \" %\")\n",
    "            print(\"The number of error produced is : \", error_produced)\n",
    "            print(\"The number of typed error corrected is : \", error_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant de comptre le nombre d'occurence de chaque mot, chaque tags et de chaque pairs (mot, tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de comptre le nombre d'occurence de chaque mot, chaque tags et de chaque\n",
    "# pairs (mot, tag)\n",
    "def make_words_tags_count(data):\n",
    "    count_words = {}\n",
    "    tags = {}\n",
    "    pairs = {}\n",
    "    for sent in data:\n",
    "        for w,t in sent:\n",
    "            if w in count_words:\n",
    "                count_words[w]+=1\n",
    "            else:\n",
    "                count_words[w]=1\n",
    "            if t in tags:\n",
    "                tags[t]+=1\n",
    "            else:\n",
    "                tags[t]=1\n",
    "            if (w,t) in pairs:\n",
    "                pairs[(w,t)]+=1\n",
    "            else:\n",
    "                pairs[(w,t)]=1\n",
    "    return count_words, tags, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant de filtrer le vocabulaire, et ainsi de restreindre la taille du vocabulaire au nombre d'occurence souhaité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de filtrer le vocabulaire, et ainsi de restreindre la taille du\n",
    "# vocabulaire au nombre d'occurence souhaité\n",
    "def filter_dict(data, limit_occ):\n",
    "    words,tags,_=make_words_tags_count(data)\n",
    "    res = []\n",
    "    for s in data:\n",
    "        sent = []\n",
    "        for w,t in s:\n",
    "            if words[w] > limit_occ:\n",
    "                sent.append((w,t))\n",
    "            else:\n",
    "                sent.append((UNK,t))\n",
    "        res.append(sent)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des fonctions permettant de calculer la matrice des observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul P(X = mot | Y = tag)\n",
    "def proba_observation_Y_X(mot, tag, words, pairs):\n",
    "    if (mot,tag) in pairs:\n",
    "        return pairs[(mot,tag)] / words[mot]\n",
    "    else:\n",
    "        return 0\n",
    "# Création du dictionnaire servant à initialiser la matrice d'observation\n",
    "def make_all_proba_observation_Y_X(data):\n",
    "    words,tags,pairs=make_words_tags_count(data)\n",
    "    res = {}\n",
    "    for (w,t),c in pairs.items():\n",
    "        res[(w,t)]=proba_observation_Y_X(w,t,words,pairs)\n",
    "    s = sum(v for k, v in res.items())\n",
    "    res = {k: v / s for k, v in res.items()}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des fonctions permettant le calcul de la matrice de transition du type :\n",
    "P(Y = a | Y = b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul P(Y = tag1 | Y = tag0)\n",
    "def proba_transition_Y1_Y0(tag1, tag0, pairs, tags):\n",
    "    if (tag1,tag0) in pairs:\n",
    "        return pairs[(tag1, tag0)] / tags[tag0]\n",
    "    else:\n",
    "        return 0\n",
    "# Compte le nombre de pairs de tags\n",
    "def make_tags_pairs(data):\n",
    "    pairs = {}\n",
    "    for s in data:\n",
    "        for i in range(len(s) - 1):\n",
    "            if (s[i+1][1], s[i][1]) in pairs:\n",
    "                pairs[s[i+1][1], s[i][1]]+=1\n",
    "            else:\n",
    "                pairs[s[i+1][1], s[i][1]]=1\n",
    "    return pairs\n",
    "\n",
    "# Création du dictionnaire servant à initialiser la matrice de transition à l'ordre 1\n",
    "def make_all_proba_transition_Y1_Y0(data):\n",
    "    _,tags,_=make_words_tags_count(data)\n",
    "    pairs=make_tags_pairs(data)\n",
    "    res = {}\n",
    "    for (y1,y0),c in pairs.items():\n",
    "        res[(y1,y0)]=proba_transition_Y1_Y0(y1,y0, pairs, tags)\n",
    "    s = sum(v for k, v in res.items())\n",
    "    res = {k: v / s for k, v in res.items()}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de toutes les fonctions permettant l'initialisation de la matrice de transition.\n",
    "Ici, il s'agit de la matrice de transition construite de la manière suivante:\n",
    "\n",
    "P(Yi = a | Yi-1 = b, Yi-2 = c) = transition.proba[a][b][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul P(Y = tag2 | Y = tag1, Y = tag0)\n",
    "def proba_transition_Y2_Y1_Y0(tag2, tag1, tag0, triplets, pairs):\n",
    "    if (tag2,tag1,tag0) in triplets:\n",
    "        return triplets[(tag2, tag1, tag0)] / pairs[(tag1, tag0)]\n",
    "    else:\n",
    "        return 0\n",
    "# Compte le nombre de triplets de tags\n",
    "def make_tags_triplets(data):\n",
    "    triplets = {}\n",
    "    for s in data:\n",
    "        for i in range(len(s) - 2):\n",
    "            if (s[i+2][1], s[i+1][1], s[i][1]) in triplets:\n",
    "                triplets[s[i+2][1], s[i+1][1], s[i][1]]+=1\n",
    "            else:\n",
    "                triplets[s[i+2][1], s[i+1][1], s[i][1]]=1\n",
    "    return triplets\n",
    "\n",
    "# Création du dictionnaire servant à initialiser la matrice de transition à l'ordre 2\n",
    "def make_all_proba_transition_Y2_Y1_Y0(data):\n",
    "    triplets=make_tags_triplets(data)\n",
    "    pairs=make_tags_pairs(data)\n",
    "    res = {}\n",
    "    for (y2,y1,y0),c in triplets.items():\n",
    "        res[(y2,y1,y0)]=proba_transition_Y2_Y1_Y0(y2,y1,y0, triplets, pairs)\n",
    "    s = sum(v for k, v in res.items())\n",
    "    res = {k: v / s for k, v in res.items()}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des probabilités de tags initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dictionnaire servant à la l'initialisation de la matrice \"Pi\" : \"initial_state_proba\"\n",
    "def makePi0(data):\n",
    "    res = {}\n",
    "    total = 0\n",
    "    for s in data:\n",
    "        if s[0][1] in res:\n",
    "            res[s[0][1]] += 1\n",
    "        else:\n",
    "            res[s[0][1]] = 1\n",
    "        total += 1\n",
    "    for k,v in res.items():\n",
    "        res[k] /= total\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'initialisation du HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du modèle HMM avec toutes les matrices de paramètres correspondantes.\n",
    "def initHMM(data):\n",
    "    count_words, count_tags, pairs = make_words_tags_count(data)\n",
    "    obs = make_all_proba_observation_Y_X(data)\n",
    "    trans_2 = make_all_proba_transition_Y1_Y0(data)\n",
    "    trans_3 = make_all_proba_transition_Y2_Y1_Y0(data)\n",
    "    return HMM([t for t,_ in count_tags.items()], [w for w,_ in count_words.items()], trans_2, trans_3, obs, makePi0(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train10 = pickle.load( open( \"../typos-data/train10.pkl\", \"rb\" ))\n",
    "data_test10 = pickle.load(open(\"../typos-data/test10.pkl\", \"rb\"))\n",
    "\n",
    "data_train20 = pickle.load(open(\"../typos-data/train20.pkl\", \"rb\"))\n",
    "data_test20 = pickle.load(open(\"../typos-data/test20.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sequences d'entrainement dans train10.pkl :  29057\n",
      "Nombre de sequences d'entrainement dans train20.pkl :  27184 \n",
      "\n",
      "Nombre de sequences de test dans test10.pkl :  1501\n",
      "Nombre de sequences de test dans train20.pkl :  1501\n"
     ]
    }
   ],
   "source": [
    "# Process des données pour le modèle naïf\n",
    "data_train10naïf = process_data(data_train10, 10)\n",
    "data_train20naïf = process_data(data_train20, 10)\n",
    "\n",
    "# Process des données pour les HMM\n",
    "data_train10hmm = filter_dict(data_train10,10)\n",
    "data_train20hmm = filter_dict(data_train20, 10)\n",
    "\n",
    "print(\"Nombre de sequences d'entrainement dans train10.pkl : \", len(data_train10))\n",
    "print(\"Nombre de sequences d'entrainement dans train20.pkl : \", len(data_train20), \"\\n\")\n",
    "print(\"Nombre de sequences de test dans test10.pkl : \", len(data_test10))\n",
    "print(\"Nombre de sequences de test dans train20.pkl : \", len(data_test10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du modèle naïf avec les données (train10.pkl & test10.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, l_tags, count_words, count_of_pairs = compute_params(data_train10naïf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de précision pour modèle naïf sur les données 10% erronnées :  90.0  %\n"
     ]
    }
   ],
   "source": [
    "accuracy = eval_model(data_test10, data_train10naïf, count_of_pairs, count_words, l_tags)\n",
    "print(\"Pourcentage de précision pour modèle naïf sur les données 10% erronnées : \", accuracy, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, l_tags, count_words, count_of_pairs = compute_params(data_train20naïf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de précision pour modèle naïf sur les données 20% erronnées :  81.9  %\n"
     ]
    }
   ],
   "source": [
    "accuracy = eval_model(data_test20, data_train20naïf, count_of_pairs, count_words, l_tags)\n",
    "print(\"Pourcentage de précision pour modèle naïf sur les données 20% erronnées : \", accuracy, \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du HMM avec les données (train10.pkl & test10.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du modèle HMM : \n",
      "\n",
      "HMM created with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialisation du modèle HMM : \\n\")\n",
    "HMM10 = initHMM(data_train10hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model(HMM first order) is :  91.5  %\n",
      "The number of error produced is :  210\n",
      "The number of typed error corrected is :  333\n"
     ]
    }
   ],
   "source": [
    "HMM10.evaluate_fst_order(data_test10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model(HMM second order) is :  94.88  %\n",
      "The number of error produced is :  129\n",
      "The number of typed error corrected is :  499\n"
     ]
    }
   ],
   "source": [
    "HMM10.evaluate_scd_order(data_test10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du HMM avec les données (train20.pkl & test20.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du modèle HMM : \n",
      "\n",
      "HMM created with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "print(\"Initialisation du modèle HMM : \\n\")\n",
    "HMM20 = initHMM(data_train20hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model(HMM first order) is :  85.04  %\n",
      "The number of error produced is :  760\n",
      "The number of typed error corrected is :  1502\n"
     ]
    }
   ],
   "source": [
    "HMM20.evaluate_fst_order(data_test20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model(HMM second order) is :  91.06  %\n",
      "The number of error produced is :  477\n",
      "The number of typed error corrected is :  2224\n"
     ]
    }
   ],
   "source": [
    "HMM20.evaluate_scd_order(data_test20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récapitulatif\n",
    "\n",
    "Que ce soit sur les données avec 10% ou 20% d'erreurs le HMM au second ordre et toujours plus performant que celui au premier ordre (ex : 94,88% contre 91,5%). Evidemment le modèle naïf implémenté pour le tp1 à été repris et testé sur ces données également. Les performances de celui-ci sont en dessous des deux modèles HMM (90% au mieux pour le modèles naïf).\n",
    "On se rend compte également que les HMM ainsi testé parviennent à corriger pas mal d'erreurs et n'en produisent pas tant que ça. Dans tous les cas des HMM implémentés ci-dessus, ceux-ci corrigent plus d'erreurs qu'il n'en produisent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
